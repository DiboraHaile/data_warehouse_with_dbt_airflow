[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]

![workflow](https://github.com/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark/actions/workflows/blank.yml/badge.svg)

<br />
<p align="center">
  <a href="https://github.com/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark">
    <img src="https://www.nicepng.com/png/full/838-8385423_implementing-speech-to-text-in-susi-ios-speech.png" alt="Logo" width="80" height="80">
  </a>

  <h3 align="center">Implementing ELT using DBT, AirFlow and Redash</h3>

  <p align="center">
Implementing ELT using DBT, AirFlow and Redash
This project attempts to produce a tool that can be used as a basis for Data WareHouse needs. It will utilize an ELT pipeline to load and transform data from the Warehouse. It will also create a dynamic dashboard for visualizing the data. To achieve these tasks, DBT will be used for transforming the data, AirFlow to automate the process and Redash for Reporting. 
    <br />
    <a href="https://www.youtube.com/playlist?list=PLy4OcwImJzBLJzLYxpxaPUmCWp8j1esvT"><strong>An Introductory on DBT </strong></a>
    <br />
    <br />
    <a href="https://anson.ucdavis.edu/~clarkf/">Dataset</a>
    ·
    <a href="https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/issues">Report Bug</a>
    ·
    <a href="https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/issues">Request Feature</a>
  </p>
</p>



<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgements">Acknowledgements</a></li>
  </ol>
</details>


<!-- ABOUT THE PROJECT -->
## About The Project

This project attempts to produce a tool that can be used as a basis for Data WareHouse needs. It will utilize an ELT pipeline to load and transform data from the Warehouse. It will also create a dynamic dashboard for visualizing the data. To achieve these tasks, DBT will be used for transforming the data, AirFlow to automate the process and Redash for Reporting. 

Here's What this module can do:
* Perform 
* and here
* ...

A list of commonly used resources that we find helpful are listed in the acknowledgements.

### Built With

Resoures that used in this project are :
* 
* 



<!-- GETTING STARTED -->
## Getting Started

You can get a local copy up and running follow these simple example steps.

### Installation

1. Clone the repo
   ```sh
   git clone https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow.git
   ```
2. Install the setup.py 



<!-- USAGE EXAMPLES -->

<!-- ROADMAP -->
## Roadmap

See the [open issues](https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/issues) for a list of proposed features (and known issues).



<!-- CONTRIBUTING -->
## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request



<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE` for more information.



<!-- CONTACT -->
## Contributers
    Dibora Haile Gebreyohannes


Project Link: [https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow.git](https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow.git)

<!-- ACKNOWLEDGEMENTS -->
## Acknowledgements
* [10 Academy](https://www.10academy.org/)
* [IsraelAbebe](https://github.com/IsraelAbebe/An-Amharic-News-Text-classification-Dataset)

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[stars-url]: https://github.com/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark/stargazers
[issues-shield]: https://img.shields.io/github/issues/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark.svg?style=for-the-badge
[issues-url]: https://github.com/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark/issues
[license-shield]: https://img.shields.io/github/license/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark.svg?style=for-the-badge
[license-url]: https://github.com/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark/blob/main/LICENSE
[contributors-shield]: https://img.shields.io/github/contributors/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark.svg?style=for-the-badge
[contributors-url]: https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/contributors
[forks-shield]: https://img.shields.io/github/forks/DiboraHaile/data_warehouse_with_dbt_airflow/.svg?style=for-the-badge
[forks-url]: https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/network/members
[stars-shield]: https://img.shields.io/github/stars/week9-Benkart/Speech-to-text-data-collection-with-Kafka-Airflow-and-Spark.svg?style=for-the-badge
[stars-url]: https://github.com/DiboraHaile/data_warehouse_with_dbt_airflow/stargazers
[product-screenshot]: images/screenshot.png
